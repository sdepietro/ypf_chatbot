# YPF Chat Station - Alcance: Feature de Voz

## Objetivo

Agregar la capacidad de **conversaciÃ³n por voz** al sistema de chat existente. El comportamiento esperado es:

- Si el humano envÃ­a **texto** â†’ el bot responde con **texto** (comportamiento actual).
- Si el humano envÃ­a **audio** â†’ el bot responde con **audio**.

Esto permite al playero practicar conversaciones habladas con el bot, simulando una interacciÃ³n real en la estaciÃ³n de servicio.

---

## Componentes TÃ©cnicos Necesarios

Para implementar voz se necesitan cuatro piezas fundamentales:

### 1. STT (Speech-to-Text)
Convertir el audio del humano a texto para que el LLM (ChatGPT) pueda procesarlo.

### 2. TTS (Text-to-Speech)
Convertir la respuesta de texto del bot a audio para que el humano la escuche.

### 3. Captura de Audio en el Browser
Usar la **MediaRecorder API** del navegador para grabar audio desde el micrÃ³fono del usuario. Esto es estÃ¡ndar y funciona en todos los browsers modernos (Chrome, Edge, Firefox, Safari).

### 4. LÃ³gica de DetecciÃ³n de Tipo de Input
El sistema debe detectar si el mensaje enviado es texto o audio, y responder en el mismo formato:

```
Humano envÃ­a texto  â†’ Bot responde texto (flujo actual, sin cambios)
Humano envÃ­a audio  â†’ STT â†’ LLM â†’ TTS â†’ Bot responde audio
```

---

## Flujo TÃ©cnico Detallado (Modo Voz)

```
1. Humano presiona botÃ³n "Grabar" en el frontend
   â””â”€â”€ MediaRecorder API captura audio del micrÃ³fono
   â””â”€â”€ Se genera un blob de audio (webm/opus o wav)

2. Humano presiona "Enviar" (o suelta el botÃ³n)
   â””â”€â”€ Audio se envÃ­a al backend (POST multipart/form-data)
   â””â”€â”€ Se persiste el archivo de audio en storage

3. Backend procesa el audio
   â””â”€â”€ STT convierte audio â†’ texto
   â””â”€â”€ Se guarda mensaje del humano (role: human, input_type: audio)
   â””â”€â”€ Se construye historial y se llama al LLM (ChatGPT)
   â””â”€â”€ Se recibe respuesta de texto del LLM

4. Backend genera audio de respuesta
   â””â”€â”€ TTS convierte texto del bot â†’ audio
   â””â”€â”€ Se persiste archivo de audio de respuesta
   â””â”€â”€ Se guarda mensaje del bot (role: bot, input_type: audio)

5. Frontend reproduce la respuesta
   â””â”€â”€ Se descarga/stream el audio
   â””â”€â”€ Se reproduce automÃ¡ticamente con <audio> o Audio API
   â””â”€â”€ Opcionalmente se muestra el texto como subtÃ­tulo
```

---

## 5 Alternativas de ImplementaciÃ³n

### Tabla Resumen

| # | Nombre | STT | TTS | Costo Estimado | Nivel |
|---|--------|-----|-----|----------------|-------|
| A | Browser Nativo | Web Speech API | Web Speech API | $0 | POC |
| B | Todo OpenAI | Whisper API | OpenAI TTS | ~$0.02/min | ProducciÃ³n |
| C | OpenAI Realtime | Realtime API (todo-en-uno) | Realtime API | ~$0.06-0.30/min | Premium |
| D | Mix EconÃ³mico | Deepgram Nova-3 | ElevenLabs / Deepgram Aura-2 | ~$0.01-0.04/min | ProducciÃ³n |
| E | Self-Hosted | Whisper local o Vosk | Kokoro-82M | Costo de GPU/server | On-premise |

---

### Alternativa A: Browser Nativo (Web Speech API)

**DescripciÃ³n:** Todo se resuelve en el navegador, sin llamadas a servicios externos de voz. El browser convierte voz a texto (SpeechRecognition API) y texto a voz (SpeechSynthesis API).

**STT:** `window.SpeechRecognition` / `webkitSpeechRecognition`
**TTS:** `window.speechSynthesis`

**Pros:**
- Costo $0 (no se paga por voz)
- ImplementaciÃ³n rÃ¡pida, todo client-side
- No requiere cambios en el backend (se envÃ­a texto como siempre)
- Bueno para validar el concepto antes de invertir

**Contras:**
- STT no funciona en Firefox ni Opera (solo Chrome/Edge/Safari parcial)
- STT requiere conexiÃ³n a internet en Chrome (envÃ­a audio a servers de Google)
- Calidad de las voces TTS es robÃ³tica y varÃ­a mucho entre browsers/OS
- No hay control sobre la voz del bot (suena distinto en cada dispositivo)
- No se persiste audio (todo efÃ­mero en el browser)
- Safari en PWA no soporta SpeechRecognition

**Compatibilidad de Browsers:**

| Feature | Chrome | Edge | Safari | Firefox | Opera |
|---------|--------|------|--------|---------|-------|
| STT (SpeechRecognition) | Parcial (v25+) | Si (v139+) | Parcial (v14.1+) | No | No |
| TTS (SpeechSynthesis) | Si (v33+) | Si | Si (v7+) | Si (v42+) | Si |

**Costo:** $0
**Complejidad de integraciÃ³n:** Baja (solo JS en frontend)
**Calidad de voz:** Baja-Media (depende del browser/OS)
**Latencia:** Baja (todo local excepto STT en Chrome)

**RecomendaciÃ³n:** Usar como POC para validar que el flujo funciona. No sirve para producciÃ³n.

---

### Alternativa B: Todo OpenAI (Whisper + TTS)

**DescripciÃ³n:** Se usa el ecosistema de OpenAI para ambas funciones: Whisper API para STT y OpenAI TTS para generar audio de la respuesta del bot. Ya usamos OpenAI para el LLM, asÃ­ que se mantiene un solo proveedor.

**STT:** OpenAI Whisper API / GPT-4o Transcribe
**TTS:** OpenAI TTS-1 / TTS-1-HD / GPT-4o-mini-TTS

**Pros:**
- Un solo proveedor (OpenAI) â†’ una sola API key, una sola factura
- Whisper tiene excelente accuracy en espaÃ±ol
- TTS tiene 6 voces naturales (Alloy, Echo, Fable, Onyx, Nova, Shimmer)
- MÃºltiples formatos de salida (MP3, Opus, AAC, FLAC, WAV)
- IntegraciÃ³n simple: ya tenemos el SDK de OpenAI en el proyecto
- Buena documentaciÃ³n y soporte

**Contras:**
- Costo por uso (se suma al costo del LLM)
- Requiere internet (cloud-only)
- Las voces son buenas pero no customizables (no voice cloning)
- Latencia: requiere dos llamadas extra al API (STT + TTS) ademÃ¡s del LLM

**Pricing Detallado:**

| Servicio | Modelo | Costo |
|----------|--------|-------|
| STT | Whisper | $0.006/min |
| STT | GPT-4o Transcribe | $0.006/min |
| STT | GPT-4o Mini Transcribe | $0.003/min |
| TTS | TTS-1 (Standard) | $15/1M caracteres |
| TTS | TTS-1-HD | $30/1M caracteres |
| TTS | GPT-4o-mini-TTS | ~$0.015/min |

**CÃ¡lculo ejemplo (1 minuto de conversaciÃ³n):**
- Humano habla 30 seg â†’ STT Whisper: $0.003
- Bot responde ~200 caracteres â†’ TTS-1: $0.003
- Total voz: ~$0.006/min (+ costo LLM existente)
- Para una conversaciÃ³n de 5 minutos: ~$0.03 solo voz

**Complejidad de integraciÃ³n:** Media (agregar endpoints de upload/download audio, llamar APIs de Whisper y TTS)
**Calidad de voz:** Alta (voces naturales, buen espaÃ±ol)
**Latencia:** Media (~1-3 seg adicionales por STT + TTS)

**RecomendaciÃ³n:** Mejor opciÃ³n calidad/precio para producciÃ³n. Mantiene todo en OpenAI.

---

### Alternativa C: OpenAI Realtime API

**DescripciÃ³n:** API de OpenAI diseÃ±ada para conversaciones de voz en tiempo real. Funciona como un pipeline unificado: recibe audio, procesa con el LLM, y devuelve audio. Todo en una conexiÃ³n WebSocket persistente.

**STT + LLM + TTS:** Todo integrado en la Realtime API

**Pros:**
- Latencia ultra-baja (streaming bidireccional)
- Pipeline unificado: no hay que orquestar STT â†’ LLM â†’ TTS manualmente
- Soporte nativo para interrupciones (el humano puede cortar al bot)
- Voice Activity Detection (VAD) incluido
- Experiencia mÃ¡s natural y conversacional

**Contras:**
- Significativamente mÃ¡s caro que la alternativa B
- Requiere WebSockets (mÃ¡s complejo que REST)
- Arquitectura diferente al flujo actual de mensajes
- DifÃ­cil de integrar con el modelo actual de persistencia (mensajes discretos)
- Los silencios tambiÃ©n cuentan si se hace streaming continuo
- El system prompt se envÃ­a con cada turno (costo adicional oculto)

**Pricing Detallado (por 1M tokens):**

| Modelo | Text Input | Text Output | Audio Input | Audio Output |
|--------|-----------|-------------|-------------|--------------|
| gpt-realtime | $4.00 | $16.00 | $32.00 | $64.00 |
| gpt-4o-mini-realtime | $0.60 | $2.40 | $10.00 | $20.00 |

**Costo por minuto (estimado):**
- Audio input: ~$0.06/min (gpt-realtime) o ~$0.02/min (mini)
- Audio output: ~$0.24/min (gpt-realtime) o ~$0.08/min (mini)
- Total gpt-realtime: ~$0.30/min
- Total gpt-4o-mini-realtime: ~$0.10/min
- Para una conversaciÃ³n de 5 minutos (mini): ~$0.50

**Complejidad de integraciÃ³n:** Alta (WebSockets, cambio de arquitectura, manejo de streaming)
**Calidad de voz:** Muy alta (la mejor de OpenAI)
**Latencia:** Muy baja (streaming en tiempo real)

**RecomendaciÃ³n:** Overkill para este proyecto. El costo es 10-50x mayor que la alternativa B, y la experiencia conversacional en tiempo real no es necesaria para un entrenamiento de playeros donde los turnos son discretos.

---

### Alternativa D: Mix EconÃ³mico (Deepgram + ElevenLabs/Deepgram Aura)

**DescripciÃ³n:** Combinar proveedores especializados en voz: Deepgram para STT y ElevenLabs o Deepgram Aura-2 para TTS. Esto permite elegir el mejor de cada categorÃ­a.

**STT:** Deepgram Nova-3
**TTS:** ElevenLabs (Starter) o Deepgram Aura-2

**Pros:**
- Deepgram Nova-3 es competitivo en accuracy y mÃ¡s barato que Whisper
- ElevenLabs tiene las voces mÃ¡s naturales del mercado
- Deepgram Aura-2 es muy econÃ³mico y con buena calidad enterprise
- $200 en crÃ©ditos gratis de Deepgram para empezar
- FacturaciÃ³n por segundo en Deepgram (mÃ¡s justo para audios cortos)

**Contras:**
- MÃºltiples proveedores: mÃ¡s API keys, mÃ¡s puntos de fallo, mÃ¡s complejidad
- ElevenLabs tiene pricing por plan ($5/mes Starter = 60K caracteres)
- Si el volumen crece, hay que gestionar mÃºltiples contratos/facturaciÃ³n
- Menos documentaciÃ³n en espaÃ±ol que OpenAI

**Pricing Detallado:**

| Servicio | Proveedor | Costo |
|----------|-----------|-------|
| STT | Deepgram Nova-3 (Pay-as-you-go) | $0.0077/min |
| STT | Deepgram Nova-3 (Growth) | $0.0065/min |
| TTS | ElevenLabs Starter | $5/mes (60K caracteres) |
| TTS | Deepgram Aura-2 | $0.030/1K caracteres |

**OpciÃ³n D1: Deepgram STT + ElevenLabs TTS**
- STT: $0.0077/min
- TTS: $5/mes fijo (cubre ~60K caracteres â‰ˆ ~60 minutos de audio)
- Bueno para volumen bajo-medio con voces premium

**OpciÃ³n D2: Deepgram STT + Deepgram Aura-2 TTS**
- STT: $0.0077/min
- TTS: $0.030/1K caracteres (~$0.03/min de audio)
- Un solo proveedor (Deepgram), pricing puro pay-as-you-go
- $200 gratis para empezar

**Complejidad de integraciÃ³n:** Media-Alta (integrar SDKs de 1-2 proveedores nuevos)
**Calidad de voz:** Alta (ElevenLabs) o Media-Alta (Deepgram Aura-2)
**Latencia:** Baja-Media (Deepgram STT es muy rÃ¡pido: ~150ms TTFB)

**RecomendaciÃ³n:** Buena opciÃ³n si se quiere maximizar calidad de voz (ElevenLabs) o minimizar costos (todo Deepgram). Agrega complejidad por usar proveedores adicionales.

---

### Alternativa E: Self-Hosted (Whisper local + Vosk / Kokoro)

**DescripciÃ³n:** Ejecutar los modelos de STT y TTS en infraestructura propia (servidor con GPU o CPU potente). No hay costos por API, pero sÃ­ por infraestructura.

**STT:** Whisper (self-hosted) o Vosk
**TTS:** Kokoro-82M (open source, Apache 2.0)

**Pros:**
- Sin costos de API (una vez montada la infra)
- Privacidad total: el audio nunca sale del servidor
- Sin lÃ­mites de uso ni rate limits
- Whisper self-hosted tiene excelente accuracy
- Kokoro-82M logra calidad comparable a modelos 5-15x mÃ¡s grandes
- Kokoro corre en CPU (no necesita GPU obligatoriamente)
- Vosk funciona 100% offline, soporta 20+ idiomas, modelos de ~50MB

**Contras:**
- Requiere infraestructura adicional (GPU recomendada para buen rendimiento)
- Setup y mantenimiento mÃ¡s complejo
- Whisper self-hosted necesita GPU para velocidad aceptable
- Vosk tiene menor accuracy que Whisper
- Kokoro tiene 26 voces pero limitadas en espaÃ±ol (foco en inglÃ©s)
- Hay que gestionar actualizaciones de modelos manualmente
- No escala tan fÃ¡cil como una API cloud

**Modelos recomendados:**

| Componente | Modelo | TamaÃ±o | Requisitos |
|------------|--------|--------|------------|
| STT | Whisper large-v3 | ~3GB | GPU (VRAM 6GB+) |
| STT | Whisper medium | ~1.5GB | GPU o CPU potente |
| STT | Vosk (es-small) | ~50MB | CPU (Raspberry Pi+) |
| TTS | Kokoro-82M | ~82M params | CPU o GPU |

**Kokoro-82M en detalle:**
- 82M parÃ¡metros (muy liviano)
- ~210x real-time en GPU (RTX 4090), ~90x en RTX 3090 Ti
- Funciona en CPU sin problemas
- API compatible con OpenAI TTS (drop-in replacement)
- Docker image disponible: `ghcr.io/eduardolat/kokoro-web:latest`
- Licencia Apache 2.0 (uso comercial libre)

**Vosk en detalle:**
- 20+ idiomas soportados (incluye espaÃ±ol)
- Streaming API para transcripciÃ³n en tiempo real
- Modelos portables de ~50MB
- Bindings para Python, Java, Node.js, C#, Go
- Funciona en Raspberry Pi, Android, iOS

**Costo estimado infraestructura:**
- GPU cloud (ej: T4 en GCP): ~$0.35/hora (~$250/mes 24/7)
- Solo CPU (Kokoro + Vosk): servidor existente podrÃ­a alcanzar
- Break-even vs API: ~500+ horas de transcripciÃ³n/mes

**Complejidad de integraciÃ³n:** Alta (setup de modelos, Docker, gestiÃ³n de GPU)
**Calidad de voz:** Media-Alta (Whisper STT excelente, Kokoro TTS bueno en inglÃ©s, regular en espaÃ±ol)
**Latencia:** Variable (depende del hardware)

**RecomendaciÃ³n:** Solo justificable si hay requerimientos de privacidad estrictos o volumen muy alto. Para este proyecto MVP, es overkill.

---

## Tabla Comparativa Final

| Criterio | A: Browser | B: OpenAI | C: Realtime | D: Mix | E: Self-Hosted |
|----------|-----------|-----------|-------------|--------|----------------|
| **Costo mensual (100 conv/mes, 3 min c/u)** | $0 | ~$2 | ~$30-90 | ~$5-10 | $0-250 (infra) |
| **Calidad STT** | Baja-Media | Alta | Muy Alta | Alta | Alta (Whisper) / Media (Vosk) |
| **Calidad TTS** | Baja | Alta | Muy Alta | Muy Alta (ElevenLabs) / Alta (Aura) | Media-Alta |
| **Latencia adicional** | ~0ms | ~1-3s | ~0.2-0.5s | ~1-2s | ~1-5s (depende HW) |
| **Complejidad** | Baja | Media | Alta | Media-Alta | Alta |
| **Dependencia terceros** | Ninguna | OpenAI | OpenAI | 1-2 proveedores | Ninguna |
| **Funciona offline** | Parcial (TTS si) | No | No | No | Si |
| **Soporte espaÃ±ol** | Depende browser | Excelente | Excelente | Bueno | Variable |
| **Escalabilidad** | N/A (client) | Alta | Alta | Alta | Limitada por HW |
| **Setup inicial** | Minutos | Horas | Dias | Horas | Dias |

---

## Cambios Necesarios en el Sistema Actual

### Base de Datos

#### Tabla `messages` - Nuevos campos

| Campo | Tipo | DescripciÃ³n |
|-------|------|-------------|
| input_type | enum(`text`, `audio`) | Tipo de input del mensaje (default: `text`) |
| audio_path | varchar(500) nullable | Path al archivo de audio en storage |
| audio_duration_ms | int nullable | DuraciÃ³n del audio en milisegundos |

```sql
ALTER TABLE messages
  ADD COLUMN input_type ENUM('text', 'audio') DEFAULT 'text' AFTER role,
  ADD COLUMN audio_path VARCHAR(500) NULL AFTER content,
  ADD COLUMN audio_duration_ms INT NULL AFTER audio_path;
```

#### Campo `meta` - Nuevos datos (mensajes con audio)

```json
{
    "model": "gpt-4o-mini",
    "prompt_tokens": 150,
    "completion_tokens": 80,
    "total_tokens": 230,
    "cost_usd": 0.000345,
    "response_time_ms": 1250,
    "stt_model": "whisper-1",
    "stt_duration_ms": 3200,
    "stt_cost_usd": 0.000032,
    "tts_model": "tts-1",
    "tts_characters": 180,
    "tts_cost_usd": 0.0027,
    "voice_total_cost_usd": 0.005732
}
```

### Storage

- Crear directorio `storage/app/audio/chats/{chat_id}/`
- Guardar archivos de audio con naming: `{message_id}_{role}.{ext}` (ej: `42_human.webm`, `43_bot.mp3`)
- Considerar limpieza periÃ³dica de audios antiguos

### API - Nuevos Endpoints / Modificaciones

#### Enviar mensaje con audio

```
POST /api/chats/{chat}/messages
Content-Type: multipart/form-data

Campos:
  - audio: file (webm/wav/mp3)  â† nuevo
  - content: string             â† existente (texto, opcional si hay audio)
```

#### Obtener audio de un mensaje

```
GET /api/chats/{chat}/messages/{message}/audio
Response: audio file (stream)
```

#### Respuesta de mensaje (modificada)

```json
{
    "status": true,
    "data": {
        "human_message": {
            "id": 42,
            "role": "human",
            "input_type": "audio",
            "content": "Hola, quiero cargar nafta super",
            "audio_url": "/api/chats/5/messages/42/audio",
            "audio_duration_ms": 3200
        },
        "bot_message": {
            "id": 43,
            "role": "bot",
            "input_type": "audio",
            "content": "Buen dia! Cuantos litros de super quiere?",
            "audio_url": "/api/chats/5/messages/43/audio",
            "audio_duration_ms": 2800
        }
    },
    "message": "OK",
    "errors": []
}
```

### Backend - Nuevo Servicio

```
app/Services/VoiceService.php
```

Responsabilidades:
- `transcribe(UploadedFile $audio): string` â†’ STT
- `synthesize(string $text): string` â†’ TTS, retorna path del audio generado
- Encapsular el proveedor elegido (facilitar cambio futuro)

### Frontend - Cambios en UI

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Chat con Cliente Apurado                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                             â”‚
â”‚  [Humano] ðŸŽ¤ Audio (3.2s)  [â–¶ Play]        â”‚
â”‚           "Hola, quiero cargar nafta super" â”‚
â”‚                                             â”‚
â”‚  [Bot]    ðŸ”Š Audio (2.8s)  [â–¶ Play]        â”‚
â”‚           "Buen dia! Cuantos litros..."     â”‚
â”‚                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  [  Escribir mensaje...  ] [ðŸŽ¤] [Enviar]   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Cambios necesarios:
- BotÃ³n de micrÃ³fono (ðŸŽ¤) junto al input de texto
- LÃ³gica de grabaciÃ³n con MediaRecorder API
- Indicador visual de "grabando..." (animaciÃ³n)
- Reproductor de audio inline para mensajes de voz
- Mostrar transcripciÃ³n como subtÃ­tulo debajo del audio
- Estado "generando respuesta de voz..." (loader)

---

## Approach Incremental Recomendado

### Fase 1: POC con Browser Nativo (Alternativa A)

**Objetivo:** Validar el concepto sin costo ni cambios en backend.

- Agregar botÃ³n de micrÃ³fono en el frontend
- Usar `webkitSpeechRecognition` para convertir voz â†’ texto
- Enviar texto al API existente (sin cambios en backend)
- Usar `speechSynthesis` para leer la respuesta del bot en voz alta
- Sin persistencia de audio

**Resultado esperado:** El playero puede hablar y escuchar, pero todo es efÃ­mero y la calidad es limitada. Sirve para validar si el feature tiene valor.

### Fase 2: ProducciÃ³n con OpenAI (Alternativa B)

**Objetivo:** Feature completo con calidad de producciÃ³n.

- MigraciÃ³n de base de datos (nuevos campos en `messages`)
- Implementar `VoiceService` con Whisper + OpenAI TTS
- Crear endpoint de upload de audio
- Crear endpoint de descarga de audio
- Actualizar frontend con MediaRecorder + reproductor
- Persistir archivos de audio
- Tracking de costos de voz en `meta`

**Resultado esperado:** Feature de voz completo, con audio persistido, buena calidad, y costos controlados (~$2/mes para uso moderado).

### Fase 3: OptimizaciÃ³n (Opcional, si el volumen lo justifica)

- Evaluar migrar a Deepgram (D) si los costos de OpenAI crecen
- Evaluar Realtime API (C) si se necesita experiencia conversacional fluida
- Evaluar self-hosted (E) si hay requisitos de privacidad

---

## Decisiones Pendientes

1. **Formato de audio del browser:** Â¿webm/opus (mÃ¡s liviano) o wav (mÃ¡s compatible)?
2. **DuraciÃ³n mÃ¡xima de audio:** Â¿Limitar a 30 seg? Â¿60 seg?
3. **Auto-play de respuestas:** Â¿Reproducir automÃ¡ticamente el audio del bot o esperar click?
4. **Modo de grabaciÃ³n:** Â¿Push-to-talk (mantener presionado) o toggle (click para iniciar/parar)?
5. **Fallback:** Si STT falla, Â¿mostrar error o pedir que repita?

---

## Referencias de Pricing

> Precios verificados a enero 2026. Consultar las pÃ¡ginas oficiales para valores actualizados.

- [OpenAI Pricing](https://platform.openai.com/docs/pricing)
- [Deepgram Pricing](https://deepgram.com/pricing)
- [ElevenLabs Pricing](https://elevenlabs.io/pricing)
- [Kokoro-82M (Hugging Face)](https://huggingface.co/hexgrad/Kokoro-82M)
- [Vosk (GitHub)](https://github.com/alphacep/vosk-api)
- [Web Speech API (MDN)](https://developer.mozilla.org/en-US/docs/Web/API/Web_Speech_API)
- [MediaRecorder API (MDN)](https://developer.mozilla.org/en-US/docs/Web/API/MediaRecorder)
